3.1 神经网络概述


3.2 神经网络表示

3.3 计算神经网络的输出

3.4 多个例子中的向量化

3.5 向量化实现的解释


3.6 激活函数
  可供选择的函数   tanh函数  
  relu是什么

3.7 为什么需要非线性激活函数

3.8 激活函数的导数
  我们看看激活函数 已经看看这些函数的斜率
  
  
3.9 神经网络的梯度下降法  

numpy是什么。

3.10 （选修）直观理解反向传播


3.11 随机初始化
  
咋办呢  多少还是没听懂。